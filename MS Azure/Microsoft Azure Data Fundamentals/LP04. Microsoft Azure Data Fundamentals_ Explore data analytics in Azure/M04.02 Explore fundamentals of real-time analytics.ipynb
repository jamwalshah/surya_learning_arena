{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# M04.02 Explore fundamentals of real-time analytics\n",
        "\n"
      ],
      "metadata": {
        "id": "fFy4M_3HSFNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unit 1 of 11\n",
        "\n"
      ],
      "metadata": {
        "id": "jInVIuHjSFKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\n",
        "\n",
        "Increased use of technology by individuals, companies, and other organizations, together with the proliferation of smart devices and Internet access has led to a massive growth in the volume of data that can be generated, captured, and analyzed. Much of this data can be processed in real-time (or at least, *near* real-time) as a perpetual *stream* of data, enabling the creation of systems that reveal instant insights and trends, or take immediate responsive action to events as they occur.\n",
        "\n"
      ],
      "metadata": {
        "id": "97VmObAHSFHV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning Objectives\n",
        "\n",
        "In this module, you'll learn about the basics of stream processing and real-time analytics, and the services in Microsoft Azure that you can use to implement real-time data processing solutions. Specifically, you'll learn how to:\n",
        "\n",
        "- Compare batch and stream processing\n",
        "- Describe common elements of streaming data solutions\n",
        "- Describe features and capabilities of Azure Stream Analytics\n",
        "- Describe features and capabilities of Spark Structured Streaming on Azure\n",
        "- Describe features and capabilities of realtime analytics in Microsoft Fabric\n",
        "\n",
        "> **Note:** This module is designed to present a conceptual overview of real-time processing and describe Azure services that can be used to build real-time analytics solutions. It is not intended to teach implementation details for creating a stream processing solution.\n",
        "\n"
      ],
      "metadata": {
        "id": "j-McVJ2tSFEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next unit: Understand batch and stream processing\n",
        "\n"
      ],
      "metadata": {
        "id": "0yNf1b1ySFB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unit 2 of 11\n",
        "\n"
      ],
      "metadata": {
        "id": "ayff_DblSE_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understand batch and stream processing\n",
        "\n",
        "Data processing is simply the conversion of raw data to meaningful information through a process. There are two general ways to process data:\n",
        "\n",
        "- *Batch processing*, in which multiple data records are collected and stored before being processed together in a single operation.\n",
        "- *Stream processing*, in which a source of data is constantly monitored and processed in real time as new data events occur.\n",
        "\n"
      ],
      "metadata": {
        "id": "m2WKnxtXSE85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Understand batch processing\n",
        "\n",
        "In batch processing, newly arriving data elements are collected and stored, and the whole group is processed together as a batch. Exactly when each group is processed can be determined in a number of ways. For example, you can process data based on a scheduled time interval (for example, every hour), or it could be triggered when a certain amount of data has arrived, or as the result of some other event.\n",
        "\n",
        "For example, suppose you want to analyze road traffic by counting the number of cars on a stretch of road. A batch processing approach to this would require that you collect the cars in a parking lot, and then count them in a single operation while they're at rest.\n",
        "\n",
        "![Cars being counted in a parking lot](https://learn.microsoft.com/en-us/training/wwl-data-ai/explore-fundamentals-stream-processing/media/batch.png)\n",
        "\n",
        "If the road is busy, with a large number of cars driving along at frequent intervals, this approach may be impractical; and note that you don't get any results until you have parked a batch of cars and counted them.\n",
        "\n",
        "A real world example of batch processing is the way that credit card companies handle billing. The customer doesn't receive a bill for each separate credit card purchase but one monthly bill for all of that month's purchases.\n",
        "\n",
        "Advantages of batch processing include:\n",
        "\n",
        "- Large volumes of data can be processed at a convenient time.\n",
        "- It can be scheduled to run at a time when computers or systems might otherwise be idle, such as overnight, or during off-peak hours.\n",
        "\n",
        "Disadvantages of batch processing include:\n",
        "\n",
        "- The time delay between ingesting the data and getting the results.\n",
        "- All of a batch job's input data must be ready before a batch can be processed. This means data must be carefully checked. Problems with data, errors, and program crashes that occur during batch jobs bring the whole process to a halt. The input data must be carefully checked before the job can be run again. Even minor data errors can prevent a batch job from running.\n",
        "\n"
      ],
      "metadata": {
        "id": "NrhDnPIGSE6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Understand stream processing\n",
        "\n",
        "In stream processing, each new piece of data is processed when it arrives. Unlike batch processing, there's no waiting until the next batch processing interval - data is processed as individual units in real-time rather than being processed a batch at a time. Stream data processing is beneficial in scenarios where new, dynamic data is generated on a continual basis.\n",
        "\n",
        "For example, a better approach to our hypothetical car counting problem might be to apply a *streaming* approach, by counting the cars in real-time as they pass:\n",
        "\n",
        "![Cars being counted as they pass](https://learn.microsoft.com/en-us/training/wwl-data-ai/explore-fundamentals-stream-processing/media/stream.gif)\n",
        "\n",
        "In this approach, you don't need to wait until all of the cars have parked to start processing them, and you can aggregate the data over time intervals; for example, by counting the number of cars that pass each minute.\n",
        "\n",
        "Real world examples of streaming data include:\n",
        "\n",
        "- A financial institution tracks changes in the stock market in real time, computes value-at-risk, and automatically rebalances portfolios based on stock price movements.\n",
        "- An online gaming company collects real-time data about player-game interactions, and feeds the data into its gaming platform. It then analyzes the data in real time, offers incentives and dynamic experiences to engage its players.\n",
        "- A real-estate website that tracks a subset of data from mobile devices, and makes real-time property recommendations of properties to visit based on their geo-location.\n",
        "\n",
        "Stream processing is ideal for time-critical operations that require an instant real-time response. For example, a system that monitors a building for smoke and heat needs to trigger alarms and unlock doors to allow residents to escape immediately in the event of a fire.\n",
        "\n"
      ],
      "metadata": {
        "id": "hfa0FxGBSE35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Understand differences between batch and streaming data\n",
        "\n",
        "Apart from the way in which batch processing and streaming processing handle data, there are other differences:\n",
        "\n",
        "- *Data scope*: Batch processing can process all the data in the dataset. Stream processing typically only has access to the most recent data received, or within a rolling time window (the last 30 seconds, for example).\n",
        "- *Data size*: Batch processing is suitable for handling large datasets efficiently. Stream processing is intended for individual records or *micro batches* consisting of few records.\n",
        "- *Performance*: *Latency* is the time taken for the data to be received and processed. The latency for batch processing is typically a few hours. Stream processing typically occurs immediately, with latency in the order of seconds or milliseconds.\n",
        "- *Analysis*: You typically use batch processing to perform complex analytics. Stream processing is used for simple response functions, aggregates, or calculations such as rolling averages.\n",
        "\n"
      ],
      "metadata": {
        "id": "R4CXOnZhSE1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Combine batch and stream processing\n",
        "\n",
        "Many large-scale analytics solutions include a mix of batch and stream processing, enabling both historical and real-time data analysis. It's common for stream processing solutions to capture real-time data, process it by filtering or aggregating it, and present it through real-time dashboards and visualizations (for example, showing the running total of cars that have passed along a road within the current hour), while also persisting the processed results in a data store for historical analysis alongside batch processed data (for example, to enable analysis of traffic volumes over the past year).\n",
        "\n",
        "Even when real-time analysis or visualization of data is not required, streaming technologies are often used to capture real-time data and store it in a data store for subsequent batch processing (this is the equivalent of redirecting all of the cars that travel along a road into a parking lot before counting them).\n",
        "\n",
        "The following diagram shows some ways in which batch and stream processing can be combined in a large-scale data analytics architecture.\n",
        "\n",
        "![A data analytics architecture that includes batch and stream processing](https://learn.microsoft.com/en-us/training/wwl-data-ai/explore-fundamentals-stream-processing/media/lambda-architecture.png)\n",
        "\n",
        "1. Data events from a streaming data source are captured in real-time.\n",
        "2. Data from other sources is ingested into a data store (often a *data lake*) for batch processing.\n",
        "3. If real-time analytics is not required, the captured streaming data is written to the data store for subsequent batch processing.\n",
        "4. When real-time analytics is required, a stream processing technology is used to prepare the streaming data for real-time analysis or visualization; often by filtering or aggregating the data over temporal windows.\n",
        "5. The non-streaming data is periodically batch processed to prepare it for analysis, and the results are persisted in an analytical data store (often referred to as a *data warehouse*) for historical analysis.\n",
        "6. The results of stream processing may also be persisted in the analytical data store to support historical analysis.\n",
        "7. Analytical and visualization tools are used to present and explore the real-time and historical data.\n",
        "\n",
        "> **Note:** Commonly used solution architectures for combined batch and stream data processing include *lambda* and *delta* architectures. Details of these architectures are beyond the scope of this course, but they incorporate technologies for both large-scale batch data processing and real-time stream processing to create an end-to-end analytical solution.\n",
        "\n"
      ],
      "metadata": {
        "id": "Nw1ugRhUSEyz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next unit: Explore common elements of stream processing architecture\n",
        "\n"
      ],
      "metadata": {
        "id": "WV-WpP_qSEwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unit 3 of 11\n",
        "\n"
      ],
      "metadata": {
        "id": "UYwbbeXLSEuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore common elements of stream processing architecture\n",
        "\n",
        "There are many technologies that you can use to implement a stream processing solution, but while specific implementation details may vary, there are common elements to most streaming architectures.\n",
        "\n"
      ],
      "metadata": {
        "id": "O8BA9s6mSErk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A general architecture for stream processing\n",
        "\n",
        "At its simplest, a high-level architecture for stream processing looks like this:\n",
        "\n",
        "![An event generates data, which is captured in a queue before being processed, and the results are written to a data store or visualization](https://learn.microsoft.com/en-us/training/wwl-data-ai/explore-fundamentals-stream-processing/media/stream-architecture.png)\n",
        "\n",
        "1. An event generates some data. This might be a signal being emitted by a sensor, a social media message being posted, a log file entry being written, or any other occurrence that results in some digital data.\n",
        "2. The generated data is captured in a streaming *source* for processing. In simple cases, the source may be a folder in a cloud data store or a table in a database. In more robust streaming solutions, the source may be a \"queue\" that encapsulates logic to ensure that event data is processed in order and that each event is processed only once.\n",
        "3. The event data is processed, often by a perpetual query that operates on the event data to select data for specific types of events, project data values, or aggregate data values over temporal (time-based) periods (or *windows*) - for example, by counting the number of sensor emissions per minute.\n",
        "4. The results of the stream processing operation are written to an output (or *sink*), which may be a file, a database table, a real-time visual dashboard, or another queue for further processing by a subsequent downstream query.\n",
        "\n"
      ],
      "metadata": {
        "id": "xhycA_cESEo_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Real-time analytics in Azure\n",
        "\n",
        "Microsoft Azure supports multiple technologies that you can use to implement real-time analytics of streaming data, including:\n",
        "\n",
        "- **Azure Stream Analytics**: A platform-as-a-service (PaaS) solution that you can use to define *streaming jobs* that ingest data from a streaming source, apply a perpetual query, and write the results to an output.\n",
        "- **Spark Structured Streaming**: An open-source library that enables you to develop complex streaming solutions on Apache Spark based services, including **Azure Synapse Analytics**, **Azure Databricks**, and **Azure HDInsight**.\n",
        "- **Azure Data Explorer**: A high-performance database and analytics service that is optimized for ingesting and querying batch or streaming data with a time-series element, and which can be used as a standalone Azure service or as an **Azure Synapse Data Explorer** runtime in an Azure Synapse Analytics workspace.\n",
        "\n"
      ],
      "metadata": {
        "id": "PJ8gkdMuSEmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### *Sources* for stream processing\n",
        "\n",
        "The following services are commonly used to ingest data for stream processing on Azure:\n",
        "\n",
        "- **Azure Event Hubs**: A data ingestion service that you can use to manage queues of event data, ensuring that each event is processed in order, exactly once.\n",
        "- **Azure IoT Hub**: A data ingestion service that is similar to Azure Event Hubs, but which is optimized for managing event data from *Internet-of-things* (IoT) devices.\n",
        "- **Azure Data Lake Store Gen 2**: A highly scalable storage service that is often used in *batch processing* scenarios, but which can also be used as a source of streaming data.\n",
        "- **Apache Kafka**: An open-source data ingestion solution that is commonly used together with Apache Spark. You can use Azure HDInsight to create a Kafka cluster.\n",
        "\n"
      ],
      "metadata": {
        "id": "UsZhBSNySEkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### *Sinks* for stream processing\n",
        "\n",
        "The output from stream processing is often sent to the following services:\n",
        "\n",
        "- **Azure Event Hubs**: Used to queue the processed data for further downstream processing.\n",
        "- **Azure Data Lake Store Gen 2** or **Azure blob storage**: Used to persist the processed results as a file.\n",
        "- **Azure SQL Database** or **Azure Synapse Analytics**, or **Azure Databricks**: Used to persist the processed results in a database table for querying and analysis.\n",
        "- **Microsoft Power BI**: Used to generate real time data visualizations in reports and dashboards.\n",
        "\n"
      ],
      "metadata": {
        "id": "9QIcRpYYSEhh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next unit: Explore Azure Stream Analytics\n",
        "\n"
      ],
      "metadata": {
        "id": "siS01_MiSEfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unit 4 of 11\n",
        "\n"
      ],
      "metadata": {
        "id": "9ZFd2CrzdFxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore Azure Stream Analytics\n",
        "\n",
        "Azure Stream Analytics is a service for complex event processing and analysis of streaming data. Stream Analytics is used to:\n",
        "\n",
        "- Ingest data from an *input*, such as an Azure event hub, Azure IoT Hub, or Azure Storage blob container.\n",
        "- Process the data by using a *query* to select, project, and aggregate data values.\n",
        "- Write the results to an *output*, such as Azure Data Lake Gen 2, Azure SQL Database, Azure Synapse Analytics, Azure Functions, Azure event hub, Microsoft Power BI, or others.\n",
        "\n",
        "![A Stream Analytics job with inputs, a query, and outputs](https://learn.microsoft.com/en-us/training/wwl-data-ai/explore-fundamentals-stream-processing/media/stream-analytics.png)\n",
        "\n",
        "Once started, a Stream Analytics query runs perpetually, processing new data as it arrives in the input and storing results in the output.\n",
        "\n",
        "Azure Stream Analytics is a great technology choice when you need to continually capture data from a streaming source, filter or aggregate it, and send the results to a data store or downstream process for analysis and reporting.\n",
        "\n"
      ],
      "metadata": {
        "id": "8PXN0tCBdFuV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Azure Stream Analytics jobs and clusters\n",
        "\n",
        "The easiest way to use Azure Stream Analytics is to create a Stream Analytics *job* in an Azure subscription, configure its input(s) and output(s), and define the query that the job will use to process the data. The query is expressed using structured query language (SQL) syntax, and can incorporate static reference data from multiple data sources to supply lookup values that can be combined with the streaming data ingested from an input.\n",
        "\n",
        "If your stream process requirements are complex or resource-intensive, you can create a Stream Analysis *cluster*, which uses the same underlying processing engine as a Stream Analytics job, but in a dedicated tenant (so your processing isn't affected by other customers) and with configurable scalability that enables you to define the right balance of throughput and cost for your specific scenario.\n",
        "\n",
        "> **Note:** To learn more about the capabilities of Azure Stream Analytics, see the [Azure Stream Analytics documentation](https://learn.microsoft.com/en-us/azure/stream-analytics/).\n",
        "\n"
      ],
      "metadata": {
        "id": "-g4NBATfdFru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next unit: Exercise: Explore Azure Stream Analytics\n",
        "\n"
      ],
      "metadata": {
        "id": "3ozAlH6ndFo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unit 5 of 11\n",
        "\n"
      ],
      "metadata": {
        "id": "akqELkJgdFl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Explore Azure Stream Analytics\n",
        "\n",
        "Now it's your opportunity to explore Azure Stream Analytics in a sample solution that aggregates streaming data from a simulated IoT device.\n",
        "\n",
        "> **Note:** To complete this lab, you will need an [Azure subscription](https://azure.microsoft.com/free) in which you have administrative access.\n",
        "\n",
        "Launch the exercise and follow the instructions.\n",
        "\n",
        "[Launch Exercise](https://aka.ms/dp900-stream-lab)\n",
        "\n"
      ],
      "metadata": {
        "id": "1Oxd8jqudFjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next unit: Explore Apache Spark on Microsoft Azure\n",
        "\n"
      ],
      "metadata": {
        "id": "j5tl3zSKdFgx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unit 6 of 11\n"
      ],
      "metadata": {
        "id": "YLWmMJ-LdFeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7G4Fj_mBdFb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TYjJCOqedFZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EE_ZenerdE5J"
      }
    }
  ]
}